{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Text Analytics Final Project:\n",
    "### Christian Literature from Protestant Reformation to the Present\n",
    "\n",
    "* John Hazelton (Jch5nb@virginia.edu) \n",
    "* DS 5001\n",
    "* December 17, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Organization into Digital Analytical Edition of Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwrVU8kZDykb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.linalg import norm\n",
    "from scipy.linalg import eigh\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.manifold import TSNE\n",
    "from gensim.models import word2vec\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style='ticks')\n",
    "pio.renderers.default = 'notebook_connected'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CAzRbscg1ziu"
   },
   "source": [
    "### Download NLTK resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "Q4Id4bNP5t4p",
    "outputId": "1be778b1-a6a6-45e5-8773-010e83904be3"
   },
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwrVU8kZDykb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwrVU8kZDykb"
   },
   "outputs": [],
   "source": [
    "OHCO = ['book_id', 'book_num', 'chap_num', 'para_num', 'sent_num', 'token_num']\n",
    "#OHCO = ['book_id', 'chap_num', 'para_num', 'sent_num', 'token_num'] #excluding book level\n",
    "corpus_dir = 'corpus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwrVU8kZDykb"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect\n",
    "Our corpus of texts vary widely in their formatting, so we manually define their chunking patterns below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "roman = '[IVXLCM]+'\n",
    "caps = \"[A-Z';, -]+\"\n",
    "chap_pats = {\n",
    "    1: { \n",
    "        'start_line': 1269,\n",
    "        'end_line': 19759,\n",
    "        'book':  re.compile('^CALVIN\\'S LETTERS\\.'),\n",
    "        'chapter': re.compile('^'+roman+'\\.\\s+\\-\\s+\\-\\s+.*$'.format(roman))\n",
    "    },\n",
    "    2: { # (weird every para starts w/ number)\n",
    "        'start_line': 1903,\n",
    "        'end_line': 61563,\n",
    "        'book':  re.compile('^BOOK\\s+[\\S]+\\.'.format(roman)),\n",
    "        'chapter': re.compile('^\\s*CHAPTER\\s+\\d*\\.'.format(roman))    \n",
    "    },\n",
    "    3: { # (Used 'FIRST STAGE' to split by book, since both begin w/ a 1st stage)\n",
    "        'start_line': 638,\n",
    "        'end_line': 12175,\n",
    "        #'book':  re.compile('^\\s+PART\\s+'+roman.format(roman)),\n",
    "        'book':  re.compile('^THE FIRST STAGE'),\n",
    "        'chapter': re.compile('^THE\\s+[\\S]+\\s+STAGE')\n",
    "    },\n",
    "    4: { # (no chapters)\n",
    "        #'start_line': 345, #USE THIS IF EXCLUDING TITLE\n",
    "        'start_line': 342,\n",
    "        'end_line': 9169,\n",
    "        'book': re.compile('^A RELATION OF THE HOLY WAR\\.'.format(roman)),\n",
    "        'chapter': re.compile('^A RELATION OF THE HOLY WAR\\.'.format(roman))\n",
    "    },\n",
    "    5: { # (no chapters)\n",
    "        'start_line': 259,\n",
    "        'end_line': 14282,\n",
    "        'book': re.compile('^RELIGIOUS AFFECTIONS\\.'),\n",
    "        'chapter': re.compile('^RELIGIOUS AFFECTIONS\\.')\n",
    "    },\n",
    "    6: {\n",
    "        'start_line': 139,\n",
    "        'end_line': 17013,\n",
    "        'book':  re.compile('^SERMON 1: .*$'),\n",
    "        'chapter': re.compile('^SERMON [0-9]+:')\n",
    "    },\n",
    "    7: {\n",
    "        'start_line': 126,\n",
    "        'end_line': 6682,\n",
    "        'book': re.compile('^CHAPTER I\\.'),\n",
    "        'chapter': re.compile('^\\s*CHAPTER '+roman+'\\.'.format(roman))\n",
    "    },\n",
    "    8: {\n",
    "        'start_line': 348,\n",
    "        'end_line': 4483,\n",
    "        'book': re.compile('CHAPTER I\\.'),\n",
    "        'chapter': re.compile('^CHAPTER '+roman+'\\.'.format(roman))\n",
    "    },\n",
    "    9: { \n",
    "        'start_line': 144,\n",
    "        'end_line': 584,\n",
    "        'book': re.compile('^I. INTRODUCTORY'),\n",
    "        'chapter': re.compile('^'+roman+'\\.\\s+.+$'.format(roman))\n",
    "    },\n",
    "    10: {\n",
    "        'start_line': 166,\n",
    "        'end_line': 782,\n",
    "        'book':  re.compile('^CHAPTER I$'),\n",
    "        'chapter': re.compile('^CHAPTER\\s+'+roman.format(roman))\n",
    "    },   \n",
    "    11: {\n",
    "        'start_line': 291,\n",
    "        'end_line': 2312,\n",
    "        'book':  re.compile('^1$'),\n",
    "        'chapter': re.compile('^[0-9]+$')\n",
    "    },\n",
    "    12: {\n",
    "        'start_line': 383,\n",
    "        'end_line': 2117,\n",
    "        'book':  re.compile('^1: TO ABSORB THE WRATH OF GOD'),\n",
    "        'chapter': re.compile('^[0-9]+:\\s+.+$')\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register and Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquire_corpus(corpus_list, chap_pats, OHCO=OHCO):\n",
    "    \n",
    "    my_lib = []\n",
    "    my_doc = []\n",
    "\n",
    "    for text_file in corpus_list:\n",
    "        \n",
    "        # Get ID from filename:\n",
    "        book_id = int(text_file.split('_')[0].split('\\\\')[-1])\n",
    "        print(\"BOOK ID\", book_id)\n",
    "        \n",
    "        # Import file as lines\n",
    "        lines = open(text_file, 'r', encoding='utf-8-sig').readlines()\n",
    "        df = pd.DataFrame(lines, columns=['line_str'])\n",
    "        df.index.name = 'line_num'\n",
    "        df.line_str = df.line_str.str.strip()\n",
    "        df['book_id'] = book_id\n",
    "        \n",
    "        # FIX CHARACTERS TO IMPROVE TOKENIZATION\n",
    "        df.line_str = df.line_str.str.replace('—', ' — ')\n",
    "        df.line_str = df.line_str.str.replace('-', ' - ')\n",
    "        \n",
    "        # Get book title, author, and year and put into LIB table (using filenames that I pre-filled with the metadata)\n",
    "        book = text_file.split('_')[3].replace('-', ' ').replace('.txt', '')\n",
    "        author = text_file.split('_')[1]\n",
    "        year = text_file.split('_')[2]\n",
    "        \n",
    "        # Remove cruft\n",
    "        a = chap_pats[book_id]['start_line'] - 1\n",
    "        b = chap_pats[book_id]['end_line'] + 1\n",
    "        df = df.iloc[a:b]\n",
    "        \n",
    "        # Chunk by book\n",
    "        book_lines = df.line_str.str.match(chap_pats[book_id]['book'])\n",
    "        book_nums = [i+1 for i in range(df.loc[book_lines].shape[0])]\n",
    "        df.loc[book_lines, 'book_num'] = book_nums\n",
    "        df.book_num = df.book_num.ffill()\n",
    "\n",
    "        # Chunk by chapter\n",
    "        chap_lines = df.line_str.str.match(chap_pats[book_id]['chapter'])\n",
    "        chap_nums = [i+1 for i in range(df.loc[chap_lines].shape[0])]\n",
    "        df.loc[chap_lines, 'chap_num'] = chap_nums\n",
    "        df.chap_num = df.chap_num.ffill()\n",
    "\n",
    "        # Clean up\n",
    "        df = df[~df.chap_num.isna()] # Remove chapter heading lines\n",
    "        #df = df[~df.book_num.isna()] # Remove book heading lines\n",
    "        df = df.loc[~chap_lines] ## Remove everything before Chapter 1 - Can edit this to remove everything before book 1\n",
    "        df['chap_num'] = df['chap_num'].astype('int')\n",
    "        #df['book_num'] = df['book_num'].fillna(0)\n",
    "        df['book_num'] = df['book_num'].astype('int')  ## Remove this line if only doing chapter-level\n",
    "\n",
    "        ### Important for book v chapter level breakdown: \n",
    "        df = df.groupby(OHCO[1:3]).line_str.apply(lambda x: '\\n'.join(x)).to_frame() # Make big string - edit subscripts to include/exclude book level\n",
    "        \n",
    "        # Split into paragraphs\n",
    "        df = df['line_str'].str.split(r'\\n\\n+', expand=True).stack().to_frame().rename(columns={0:'para_str'})\n",
    "        df.index.names = OHCO[1:4] ## Edit subscript limits on this for chunking by book vs chapter level\n",
    "        df['para_str'] = df['para_str'].str.replace(r'\\n', ' ').str.strip()\n",
    "        df = df[~df['para_str'].str.match(r'^\\s*$')] # Remove empty paragraphs\n",
    "        \n",
    "        # Set index\n",
    "        df['book_id'] = book_id\n",
    "        df = df.reset_index().set_index(OHCO[:4])\n",
    "\n",
    "        # Register\n",
    "        my_lib.append((book_id, book, author, year, text_file))\n",
    "        my_doc.append(df)\n",
    "\n",
    "    docs = pd.concat(my_doc)\n",
    "    library = pd.DataFrame(my_lib, columns=['book_id', 'book', 'author', 'year', 'book_file']).set_index('book_id')\n",
    "    print(\"Done.\")\n",
    "    return library, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOOK ID 10\n",
      "BOOK ID 11\n",
      "BOOK ID 12\n",
      "BOOK ID 1\n",
      "BOOK ID 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\AppData\\Local\\Temp/ipykernel_23908/1714270858.py:59: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOOK ID 3\n",
      "BOOK ID 4\n",
      "BOOK ID 5\n",
      "BOOK ID 6\n",
      "BOOK ID 7\n",
      "BOOK ID 8\n",
      "BOOK ID 9\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "corpus = [text for text in sorted(glob(corpus_dir+'/*.txt'))]\n",
    "LIB, DOC = acquire_corpus(corpus, chap_pats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>book_file</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Four Loves</td>\n",
       "      <td>Lewis</td>\n",
       "      <td>1960</td>\n",
       "      <td>corpus\\10_Lewis_1960_The-Four-Loves.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Don't Waste Your Life</td>\n",
       "      <td>Piper</td>\n",
       "      <td>2003</td>\n",
       "      <td>corpus\\11_Piper_2003_Don't-Waste-Your-Life.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Fifty Reasons Why Jesus Came to Die</td>\n",
       "      <td>Piper</td>\n",
       "      <td>2004</td>\n",
       "      <td>corpus\\12_Piper_2004_Fifty-Reasons-Why-Jesus-C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Letters of John Calvin, Volume I</td>\n",
       "      <td>Calvin</td>\n",
       "      <td>1536</td>\n",
       "      <td>corpus\\1_Calvin_1536_Letters-of-John-Calvin,-V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Institutes of the Christian Religion</td>\n",
       "      <td>Calvin</td>\n",
       "      <td>1541</td>\n",
       "      <td>corpus\\2_Calvin_1541_The-Institutes-of-the-Chr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Pilgrim's Progress</td>\n",
       "      <td>Bunyan</td>\n",
       "      <td>1678</td>\n",
       "      <td>corpus\\3_Bunyan_1678_The-Pilgrim's-Progress.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Holy War</td>\n",
       "      <td>Bunyan</td>\n",
       "      <td>1682</td>\n",
       "      <td>corpus\\4_Bunyan_1682_The-Holy-War.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Religious Affections</td>\n",
       "      <td>Edwards</td>\n",
       "      <td>1746</td>\n",
       "      <td>corpus\\5_Edwards_1746_Religious-Affections.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Select Sermons</td>\n",
       "      <td>Edwards</td>\n",
       "      <td>1750</td>\n",
       "      <td>corpus\\6_Edwards_1750_Select-Sermons.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Evidences of the Christian Religion</td>\n",
       "      <td>Alexander</td>\n",
       "      <td>1832</td>\n",
       "      <td>corpus\\7_Alexander_1832_Evidences-of-the-Chris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Outlines of Moral Science</td>\n",
       "      <td>Alexander</td>\n",
       "      <td>1854</td>\n",
       "      <td>corpus\\8_Alexander_1854_Outlines-of-Moral-Scie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Problem of Pain</td>\n",
       "      <td>Lewis</td>\n",
       "      <td>1940</td>\n",
       "      <td>corpus\\9_Lewis_1940_The-Problem-of-Pain.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             book     author  year  \\\n",
       "book_id                                                              \n",
       "10                                 The Four Loves      Lewis  1960   \n",
       "11                          Don't Waste Your Life      Piper  2003   \n",
       "12            Fifty Reasons Why Jesus Came to Die      Piper  2004   \n",
       "1                Letters of John Calvin, Volume I     Calvin  1536   \n",
       "2        The Institutes of the Christian Religion     Calvin  1541   \n",
       "3                          The Pilgrim's Progress     Bunyan  1678   \n",
       "4                                    The Holy War     Bunyan  1682   \n",
       "5                            Religious Affections    Edwards  1746   \n",
       "6                                  Select Sermons    Edwards  1750   \n",
       "7             Evidences of the Christian Religion  Alexander  1832   \n",
       "8                       Outlines of Moral Science  Alexander  1854   \n",
       "9                             The Problem of Pain      Lewis  1940   \n",
       "\n",
       "                                                 book_file  \n",
       "book_id                                                     \n",
       "10                 corpus\\10_Lewis_1960_The-Four-Loves.txt  \n",
       "11          corpus\\11_Piper_2003_Don't-Waste-Your-Life.txt  \n",
       "12       corpus\\12_Piper_2004_Fifty-Reasons-Why-Jesus-C...  \n",
       "1        corpus\\1_Calvin_1536_Letters-of-John-Calvin,-V...  \n",
       "2        corpus\\2_Calvin_1541_The-Institutes-of-the-Chr...  \n",
       "3          corpus\\3_Bunyan_1678_The-Pilgrim's-Progress.txt  \n",
       "4                    corpus\\4_Bunyan_1682_The-Holy-War.txt  \n",
       "5           corpus\\5_Edwards_1746_Religious-Affections.txt  \n",
       "6                 corpus\\6_Edwards_1750_Select-Sermons.txt  \n",
       "7        corpus\\7_Alexander_1832_Evidences-of-the-Chris...  \n",
       "8        corpus\\8_Alexander_1854_Outlines-of-Moral-Scie...  \n",
       "9              corpus\\9_Lewis_1940_The-Problem-of-Pain.txt  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>para_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>book_num</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>1</th>\n",
       "      <th>12</th>\n",
       "      <th>54</th>\n",
       "      <td>Many, when they think they are converted, seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>13</th>\n",
       "      <td>A nobler analogy, sanctioned by the constant t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>39</th>\n",
       "      <th>9</th>\n",
       "      <td>[_Calvin's Lat. Corresp._, Opera, tom. ix. p. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>1</th>\n",
       "      <th>13</th>\n",
       "      <th>5</th>\n",
       "      <td>And thus the apostle proves, that no flesh can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <th>34</th>\n",
       "      <th>53</th>\n",
       "      <td>[262] Ephes. 1:20; Phil. 2:9; 1 Cor. 15:27; Ep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>94</th>\n",
       "      <th>15</th>\n",
       "      <td>Adieu, my excellent and highly esteemed brothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>58</th>\n",
       "      <td>So here is the question to test whether you ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>13</th>\n",
       "      <th>19</th>\n",
       "      <td>And there are actual wickednesses without numb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <th>29</th>\n",
       "      <td>How happy would you be if your hearts were but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <th>1</th>\n",
       "      <th>26</th>\n",
       "      <th>10</th>\n",
       "      <td>For Christ has entered... into heaven itself, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             para_str\n",
       "book_id book_num chap_num para_num                                                   \n",
       "6       1        12       54        Many, when they think they are converted, seem...\n",
       "9       1        3        13        A nobler analogy, sanctioned by the constant t...\n",
       "1       1        39       9         [_Calvin's Lat. Corresp._, Opera, tom. ix. p. ...\n",
       "6       1        13       5         And thus the apostle proves, that no flesh can...\n",
       "2       2        34       53        [262] Ephes. 1:20; Phil. 2:9; 1 Cor. 15:27; Ep...\n",
       "1       1        94       15        Adieu, my excellent and highly esteemed brothe...\n",
       "11      1        2        58        So here is the question to test whether you ha...\n",
       "6       1        13       19        And there are actual wickednesses without numb...\n",
       "                 16       29        How happy would you be if your hearts were but...\n",
       "12      1        26       10        For Christ has entered... into heaven itself, ..."
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DOC.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize and Annotate\n",
    "Here we use NLTK functions to tokenize & annotate our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc_df, OHCO=OHCO, remove_pos_tuple=False, ws=False):\n",
    "    \n",
    "    # Paragraphs to Sentences\n",
    "    df = doc_df.para_str\\\n",
    "        .apply(lambda x: pd.Series(nltk.sent_tokenize(x)))\\\n",
    "        .stack()\\\n",
    "        .to_frame()\\\n",
    "        .rename(columns={0:'sent_str'})\n",
    "    \n",
    "    # Sentences to Tokens\n",
    "    # Local function to pick tokenizer\n",
    "    def word_tokenize(x):\n",
    "        if ws:\n",
    "            s = pd.Series(nltk.pos_tag(nltk.WhitespaceTokenizer().tokenize(x)))\n",
    "        else:\n",
    "            s = pd.Series(nltk.pos_tag(nltk.word_tokenize(x))) # Discards stuff in between\n",
    "        return s\n",
    "            \n",
    "    df = df.sent_str\\\n",
    "        .apply(word_tokenize)\\\n",
    "        .stack()\\\n",
    "        .to_frame()\\\n",
    "        .rename(columns={0:'pos_tuple'})\n",
    "    \n",
    "    # Grab info from tuple\n",
    "    df['pos'] = df.pos_tuple.apply(lambda x: x[1])\n",
    "    df['token_str'] = df.pos_tuple.apply(lambda x: x[0])\n",
    "    if remove_pos_tuple:\n",
    "        df = df.drop('pos_tuple', 1)\n",
    "    \n",
    "    # Add index\n",
    "    df.index.names = OHCO\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time #show runtime\n",
    "TOKEN = tokenize(DOC, ws=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>book_num</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">10</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>(Introduction, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>Introduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(``, ``)</td>\n",
       "      <td>``</td>\n",
       "      <td>``</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(God, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>God</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(is, VBZ)</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(love, RBR)</td>\n",
       "      <td>RBR</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                pos_tuple  \\\n",
       "book_id book_num chap_num para_num sent_num token_num                       \n",
       "10      1        1        1        0        0          (Introduction, NN)   \n",
       "                          2        0        0                    (``, ``)   \n",
       "                                            1                  (God, NNP)   \n",
       "                                            2                   (is, VBZ)   \n",
       "                                            3                 (love, RBR)   \n",
       "\n",
       "                                                       pos     token_str  \n",
       "book_id book_num chap_num para_num sent_num token_num                     \n",
       "10      1        1        1        0        0           NN  Introduction  \n",
       "                          2        0        0           ``            ``  \n",
       "                                            1          NNP           God  \n",
       "                                            2          VBZ            is  \n",
       "                                            3          RBR          love  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Reduce\n",
    "\n",
    "Extract a vocabulary from the TOKEN table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\AppData\\Local\\Temp/ipykernel_23908/1858674674.py:1: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TOKEN['term_str'] = TOKEN['token_str'].str.lower().str.replace('[\\W_]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = TOKEN.term_str.value_counts().to_frame()\\\n",
    "    .rename(columns={'index':'term_str', 'term_str':'n'})\\\n",
    "    .sort_index().reset_index().rename(columns={'index':'term_str'})\n",
    "VOCAB.index.name = 'term_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "colab_type": "code",
    "id": "3iYsuby6FYYR",
    "outputId": "b29dd1cd-a82a-44be-e21c-aa9b7e1e4933"
   },
   "outputs": [],
   "source": [
    "VOCAB['num'] = VOCAB.term_str.str.match(\"\\d+\").astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "colab_type": "code",
    "id": "3iYsuby6FYYR",
    "outputId": "b29dd1cd-a82a-44be-e21c-aa9b7e1e4933"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>288641</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1566</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term_str       n  num\n",
       "term_id                      \n",
       "0                 288641    0\n",
       "1              0       1    1\n",
       "2             01       1    1\n",
       "3              1    1566    1\n",
       "4             10     256    1"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bDSH9L2TXGzH",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Annotate VOCAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using NLTK's built in stopword list for English. We also add a few of our own stopwords - these include repeated names & locations mentioned in headings & footings of John Calvin's letters, etc. We can always further add/subtract from this list as we see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RG-5qYDR1YC2"
   },
   "outputs": [],
   "source": [
    "sw = pd.DataFrame(nltk.corpus.stopwords.words('english'), columns=['term_str'])\n",
    "\n",
    "# Add our own stopwords:\n",
    "stop_list = {'term_str': ['geneva', 'charles', 'francis', 'calvin', 'strasbourg', 'france', 'caroli']}\n",
    "sw = sw.append(pd.DataFrame(stop_list))\n",
    "\n",
    "sw = sw.reset_index().set_index('term_str')\n",
    "sw.columns = ['dummy']\n",
    "sw.dummy = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>me</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>myself</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>we</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>francis</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calvin</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strasbourg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>france</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caroli</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            dummy\n",
       "term_str         \n",
       "i               1\n",
       "me              1\n",
       "my              1\n",
       "myself          1\n",
       "we              1\n",
       "...           ...\n",
       "francis         1\n",
       "calvin          1\n",
       "strasbourg      1\n",
       "france          1\n",
       "caroli          1\n",
       "\n",
       "[186 rows x 1 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cVJUOP9l2AS7"
   },
   "outputs": [],
   "source": [
    "VOCAB['stop'] = VOCAB.term_str.map(sw.dummy)\n",
    "VOCAB['stop'] = VOCAB['stop'].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "colab_type": "code",
    "id": "QXcA9xyY4JF_",
    "outputId": "340d1dab-1901-4eeb-b9d8-a269eba90dea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12209</th>\n",
       "      <td>francis</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13677</th>\n",
       "      <td>his</td>\n",
       "      <td>14732</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26412</th>\n",
       "      <td>them</td>\n",
       "      <td>7846</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26419</th>\n",
       "      <td>then</td>\n",
       "      <td>2908</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27517</th>\n",
       "      <td>under</td>\n",
       "      <td>1551</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term_str      n  num  stop\n",
       "term_id                           \n",
       "12209    francis     62    0     1\n",
       "13677        his  14732    0     1\n",
       "26412       them   7846    0     1\n",
       "26419       then   2908    0     1\n",
       "27517      under   1551    0     1"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB[VOCAB.stop == 1].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stopwords & Numbers from VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = VOCAB[VOCAB.stop == 0]\n",
    "VOCAB = VOCAB[VOCAB.num == 0]\n",
    "VOCAB = VOCAB[VOCAB.term_str != ''] # remove empty string term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12782</th>\n",
       "      <td>god</td>\n",
       "      <td>13132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28025</th>\n",
       "      <td>us</td>\n",
       "      <td>5896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5965</th>\n",
       "      <td>christ</td>\n",
       "      <td>5738</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17181</th>\n",
       "      <td>may</td>\n",
       "      <td>4635</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18869</th>\n",
       "      <td>one</td>\n",
       "      <td>4431</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term_str      n  num  stop\n",
       "term_id                           \n",
       "12782        god  13132    0     0\n",
       "28025         us   5896    0     0\n",
       "5965      christ   5738    0     0\n",
       "17181        may   4635    0     0\n",
       "18869        one   4431    0     0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.sort_values(by='n', ascending=False).head(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add (Porter) Stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mE_YGklKXSYn"
   },
   "outputs": [],
   "source": [
    "#Add Porter stems using the PorterStemmer module:\n",
    "stemmer1 = PorterStemmer()\n",
    "VOCAB['stem_porter'] = VOCAB.term_str.apply(stemmer1.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "colab_type": "code",
    "id": "dY__Bq0yXqbj",
    "outputId": "eddcdafe-e378-4f7b-ac6b-1fc41ef64fbb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "      <th>stem_porter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9756</th>\n",
       "      <td>dulled</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18692</th>\n",
       "      <td>obstruction</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>obstruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26237</th>\n",
       "      <td>tempations</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>tempat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28036</th>\n",
       "      <td>uselessly</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>uselessli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17455</th>\n",
       "      <td>metrical</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>metric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22836</th>\n",
       "      <td>revenger</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reveng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25280</th>\n",
       "      <td>stirs</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>stir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25725</th>\n",
       "      <td>summer</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8453</th>\n",
       "      <td>depicted</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>depict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7046</th>\n",
       "      <td>consul</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>consul</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            term_str   n  num  stop stem_porter\n",
       "term_id                                        \n",
       "9756          dulled   1    0     0        dull\n",
       "18692    obstruction   3    0     0    obstruct\n",
       "26237     tempations   1    0     0      tempat\n",
       "28036      uselessly   2    0     0   uselessli\n",
       "17455       metrical   1    0     0      metric\n",
       "22836       revenger   1    0     0      reveng\n",
       "25280          stirs   8    0     0        stir\n",
       "25725         summer  18    0     0      summer\n",
       "8453        depicted   4    0     0      depict\n",
       "7046          consul   5    0     0      consul"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add term_id to TOKEN table\n",
    "\n",
    "We need to do this to combine the VOCAB and TOKEN tables more efficiently.\n",
    "We use `.map()` because TOKEN and VOCAB do not share an index at this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = VOCAB[~VOCAB.term_str.isna()]\n",
    "VOCAB = VOCAB[VOCAB.term_str != '']\n",
    "TOKEN = TOKEN[~TOKEN.term_str.isna()]\n",
    "TOKEN = TOKEN[TOKEN.term_str != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN['term_id'] = TOKEN.term_str.map(VOCAB.reset_index().set_index('term_str').term_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "      <th>term_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>book_num</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">10</th>\n",
       "      <th rowspan=\"10\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"10\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>(Introduction, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>introduction</td>\n",
       "      <td>15236.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <td>(God, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>God</td>\n",
       "      <td>god</td>\n",
       "      <td>12782.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(is, VBZ)</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(love, RBR)</td>\n",
       "      <td>RBR</td>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "      <td>16648.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(says, VBZ)</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>says</td>\n",
       "      <td>says</td>\n",
       "      <td>23510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(St., NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>St.</td>\n",
       "      <td>st</td>\n",
       "      <td>25076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(John, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>John</td>\n",
       "      <td>john</td>\n",
       "      <td>15574.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>(When, WRB)</td>\n",
       "      <td>WRB</td>\n",
       "      <td>When</td>\n",
       "      <td>when</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(I, PRP)</td>\n",
       "      <td>PRP</td>\n",
       "      <td>I</td>\n",
       "      <td>i</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(first, RB)</td>\n",
       "      <td>RB</td>\n",
       "      <td>first</td>\n",
       "      <td>first</td>\n",
       "      <td>11752.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                pos_tuple  \\\n",
       "book_id book_num chap_num para_num sent_num token_num                       \n",
       "10      1        1        1        0        0          (Introduction, NN)   \n",
       "                          2        0        1                  (God, NNP)   \n",
       "                                            2                   (is, VBZ)   \n",
       "                                            3                 (love, RBR)   \n",
       "                                            6                 (says, VBZ)   \n",
       "                                            7                  (St., NNP)   \n",
       "                                            8                 (John, NNP)   \n",
       "                                   1        0                 (When, WRB)   \n",
       "                                            1                    (I, PRP)   \n",
       "                                            2                 (first, RB)   \n",
       "\n",
       "                                                       pos     token_str  \\\n",
       "book_id book_num chap_num para_num sent_num token_num                      \n",
       "10      1        1        1        0        0           NN  Introduction   \n",
       "                          2        0        1          NNP           God   \n",
       "                                            2          VBZ            is   \n",
       "                                            3          RBR          love   \n",
       "                                            6          VBZ          says   \n",
       "                                            7          NNP           St.   \n",
       "                                            8          NNP          John   \n",
       "                                   1        0          WRB          When   \n",
       "                                            1          PRP             I   \n",
       "                                            2           RB         first   \n",
       "\n",
       "                                                           term_str  term_id  \n",
       "book_id book_num chap_num para_num sent_num token_num                         \n",
       "10      1        1        1        0        0          introduction  15236.0  \n",
       "                          2        0        1                   god  12782.0  \n",
       "                                            2                    is      NaN  \n",
       "                                            3                  love  16648.0  \n",
       "                                            6                  says  23510.0  \n",
       "                                            7                    st  25076.0  \n",
       "                                            8                  john  15574.0  \n",
       "                                   1        0                  when      NaN  \n",
       "                                            1                     i      NaN  \n",
       "                                            2                 first  11752.0  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Most Frequently Associated POS for each Term in VOCAB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['pos_max'] = TOKEN.groupby(['term_id', 'pos']).pos.count().unstack().idxmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "      <th>stem_porter</th>\n",
       "      <th>pos_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28643</th>\n",
       "      <td>wakes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>wake</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20075</th>\n",
       "      <td>pia</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pia</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17718</th>\n",
       "      <td>mocked</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mock</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27740</th>\n",
       "      <td>unless</td>\n",
       "      <td>633</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unless</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6157</th>\n",
       "      <td>clears</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>clear</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8478</th>\n",
       "      <td>deprecated</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>deprec</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14216</th>\n",
       "      <td>immorality</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>immor</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23232</th>\n",
       "      <td>saccharine</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>saccharin</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24878</th>\n",
       "      <td>spatial</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>spatial</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10417</th>\n",
       "      <td>enslaving</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>enslav</td>\n",
       "      <td>VBG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           term_str    n  num  stop stem_porter pos_max\n",
       "term_id                                                \n",
       "28643         wakes    2    0     0        wake     NNS\n",
       "20075           pia    1    0     0         pia     VBP\n",
       "17718        mocked   20    0     0        mock     VBN\n",
       "27740        unless  633    0     0      unless      IN\n",
       "6157         clears    6    0     0       clear     VBZ\n",
       "8478     deprecated    2    0     0      deprec     VBD\n",
       "14216    immorality    2    0     0       immor      NN\n",
       "23232    saccharine    1    0     0   saccharin      JJ\n",
       "24878       spatial    1    0     0     spatial      JJ\n",
       "10417     enslaving    1    0     0      enslav     VBG"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup for BOW & TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_method = 'n' # 'c' or 'n' # n = n tokens, c = distinct token (term) count\n",
    "tf_method = 'sum' # sum, max, log, double_norm, raw, binary\n",
    "tf_norm_k = .5 # only used for double_norm\n",
    "idf_method = 'standard' # standard, max, smooth\n",
    "gradient_cmap = 'YlGnBu' # YlGn, GnBu, YlGnBu; For tables; see https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html \n",
    "\n",
    "OHCO = ['book_id', 'book_num', 'chap_num', 'para_num', 'sent_num', 'token_num']\n",
    "SENTS = OHCO[:5]\n",
    "PARAS = OHCO[:4]\n",
    "CHAPS = OHCO[:3]\n",
    "BOOKS = OHCO[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Term Rank to VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'term_rank' not in VOCAB.columns:\n",
    "    VOCAB = VOCAB.sort_values('n', ascending=False).reset_index()\n",
    "    VOCAB.index.name = 'term_rank'\n",
    "    VOCAB = VOCAB.reset_index()\n",
    "    VOCAB = VOCAB.set_index('term_id')\n",
    "    VOCAB['term_rank'] = VOCAB['term_rank'] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternate Rank\n",
    "The `term_rank` above^ assigns different ranks to words w/ the same frequency, which occurs in the long tail, e.g. with words that appear once.\n",
    "We will now add a `term_rank2` that groups words by term count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rank = VOCAB.n.value_counts()\\\n",
    "    .sort_index(ascending=False).reset_index().reset_index()\\\n",
    "    .rename(columns={'level_0':'term_rank2', 'index':'n', 'n':'nn'})\\\n",
    "    .set_index('n')\n",
    "\n",
    "VOCAB['term_rank2'] = VOCAB.n.map(new_rank.term_rank2) + 1\n",
    "VOCAB['p'] = VOCAB.n / VOCAB.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_rank</th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "      <th>stem_porter</th>\n",
       "      <th>pos_max</th>\n",
       "      <th>term_rank2</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3956</th>\n",
       "      <td>15915</td>\n",
       "      <td>avows</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>avow</td>\n",
       "      <td>NNS</td>\n",
       "      <td>620</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19630</th>\n",
       "      <td>11155</td>\n",
       "      <td>peaceably</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>peaceabl</td>\n",
       "      <td>RB</td>\n",
       "      <td>618</td>\n",
       "      <td>0.000147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23639</th>\n",
       "      <td>94</td>\n",
       "      <td>scripture</td>\n",
       "      <td>1025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>scriptur</td>\n",
       "      <td>NNP</td>\n",
       "      <td>90</td>\n",
       "      <td>0.037550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16126</th>\n",
       "      <td>606</td>\n",
       "      <td>learn</td>\n",
       "      <td>222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>learn</td>\n",
       "      <td>VB</td>\n",
       "      <td>401</td>\n",
       "      <td>0.008133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21696</th>\n",
       "      <td>25018</td>\n",
       "      <td>quæs</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>quæ</td>\n",
       "      <td>NNP</td>\n",
       "      <td>621</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term_rank   term_str     n  num  stop stem_porter pos_max  \\\n",
       "term_id                                                              \n",
       "3956         15915      avows     2    0     0        avow     NNS   \n",
       "19630        11155  peaceably     4    0     0    peaceabl      RB   \n",
       "23639           94  scripture  1025    0     0    scriptur     NNP   \n",
       "16126          606      learn   222    0     0       learn      VB   \n",
       "21696        25018       quæs     1    0     0         quæ     NNP   \n",
       "\n",
       "         term_rank2         p  \n",
       "term_id                        \n",
       "3956            620  0.000073  \n",
       "19630           618  0.000147  \n",
       "23639            90  0.037550  \n",
       "16126           401  0.008133  \n",
       "21696           621  0.000037  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Zipf's K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zipf's Law:\n",
    "\n",
    "$f \\propto \\frac{1}{r} $\n",
    "\n",
    "$k =  fr$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['zipf_k'] = VOCAB.n * VOCAB.term_rank\n",
    "VOCAB['zipf_k2'] = VOCAB.n * VOCAB.term_rank2\n",
    "VOCAB['zipf_k3'] = VOCAB.p * VOCAB.term_rank2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOCAB Entropy\n",
    "Compute P of VOCAB - This is the prior, or marginal, probability of a term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['p2'] = VOCAB.n / VOCAB.n.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Entropy of VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H \t= 11.714866997124313\n",
      "H_max \t= 14.736454784066483\n",
      "R \t= 21%\n"
     ]
    }
   ],
   "source": [
    "VOCAB['h'] = VOCAB.p2 * np.log2(1/VOCAB.p2) # Self entropy of each word \n",
    "H = VOCAB.h.sum()\n",
    "N_v = VOCAB.shape[0]\n",
    "H_max = np.log2(N_v)\n",
    "R = round(1 - (H/H_max), 2) * 100\n",
    "\n",
    "print(\"H \\t= {}\\nH_max \\t= {}\\nR \\t= {}%\".format(H, H_max, int(R)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_rank</th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "      <th>stem_porter</th>\n",
       "      <th>pos_max</th>\n",
       "      <th>term_rank2</th>\n",
       "      <th>p</th>\n",
       "      <th>zipf_k</th>\n",
       "      <th>zipf_k2</th>\n",
       "      <th>zipf_k3</th>\n",
       "      <th>p2</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8164</th>\n",
       "      <td>2394</td>\n",
       "      <td>deeply</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>deepli</td>\n",
       "      <td>RB</td>\n",
       "      <td>568</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>129276</td>\n",
       "      <td>30672</td>\n",
       "      <td>1.123640</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17201</th>\n",
       "      <td>10365</td>\n",
       "      <td>meals</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>meal</td>\n",
       "      <td>NNS</td>\n",
       "      <td>617</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>51825</td>\n",
       "      <td>3085</td>\n",
       "      <td>0.113016</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21484</th>\n",
       "      <td>13419</td>\n",
       "      <td>purposeful</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>purpos</td>\n",
       "      <td>JJ</td>\n",
       "      <td>619</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>40257</td>\n",
       "      <td>1857</td>\n",
       "      <td>0.068029</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17831</th>\n",
       "      <td>24199</td>\n",
       "      <td>montaigne</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>montaign</td>\n",
       "      <td>NNP</td>\n",
       "      <td>621</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>24199</td>\n",
       "      <td>621</td>\n",
       "      <td>0.022750</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14536</th>\n",
       "      <td>25896</td>\n",
       "      <td>incontestable</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>incontest</td>\n",
       "      <td>JJ</td>\n",
       "      <td>621</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>25896</td>\n",
       "      <td>621</td>\n",
       "      <td>0.022750</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term_rank       term_str   n  num  stop stem_porter pos_max  \\\n",
       "term_id                                                                \n",
       "8164          2394         deeply  54    0     0      deepli      RB   \n",
       "17201        10365          meals   5    0     0        meal     NNS   \n",
       "21484        13419     purposeful   3    0     0      purpos      JJ   \n",
       "17831        24199      montaigne   1    0     0    montaign     NNP   \n",
       "14536        25896  incontestable   1    0     0   incontest      JJ   \n",
       "\n",
       "         term_rank2         p  zipf_k  zipf_k2   zipf_k3        p2         h  \n",
       "term_id                                                                       \n",
       "8164            568  0.001978  129276    30672  1.123640  0.000072  0.000989  \n",
       "17201           617  0.000183   51825     3085  0.113016  0.000007  0.000114  \n",
       "21484           619  0.000110   40257     1857  0.068029  0.000004  0.000072  \n",
       "17831           621  0.000037   24199      621  0.022750  0.000001  0.000026  \n",
       "14536           621  0.000037   25896      621  0.022750  0.000001  0.000026  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_rank</th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "      <th>stem_porter</th>\n",
       "      <th>pos_max</th>\n",
       "      <th>term_rank2</th>\n",
       "      <th>p</th>\n",
       "      <th>zipf_k</th>\n",
       "      <th>zipf_k2</th>\n",
       "      <th>zipf_k3</th>\n",
       "      <th>p2</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12782</th>\n",
       "      <td>1</td>\n",
       "      <td>god</td>\n",
       "      <td>13132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>god</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "      <td>0.481079</td>\n",
       "      <td>13132</td>\n",
       "      <td>13132</td>\n",
       "      <td>0.481079</td>\n",
       "      <td>0.017468</td>\n",
       "      <td>0.101998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28025</th>\n",
       "      <td>2</td>\n",
       "      <td>us</td>\n",
       "      <td>5896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>us</td>\n",
       "      <td>PRP</td>\n",
       "      <td>2</td>\n",
       "      <td>0.215994</td>\n",
       "      <td>11792</td>\n",
       "      <td>11792</td>\n",
       "      <td>0.431989</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.054856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5965</th>\n",
       "      <td>3</td>\n",
       "      <td>christ</td>\n",
       "      <td>5738</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>christ</td>\n",
       "      <td>NNP</td>\n",
       "      <td>3</td>\n",
       "      <td>0.210206</td>\n",
       "      <td>17214</td>\n",
       "      <td>17214</td>\n",
       "      <td>0.630619</td>\n",
       "      <td>0.007633</td>\n",
       "      <td>0.053685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17181</th>\n",
       "      <td>4</td>\n",
       "      <td>may</td>\n",
       "      <td>4635</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>may</td>\n",
       "      <td>MD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.169799</td>\n",
       "      <td>18540</td>\n",
       "      <td>18540</td>\n",
       "      <td>0.679196</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>0.045264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18869</th>\n",
       "      <td>5</td>\n",
       "      <td>one</td>\n",
       "      <td>4431</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>one</td>\n",
       "      <td>CD</td>\n",
       "      <td>5</td>\n",
       "      <td>0.162326</td>\n",
       "      <td>22155</td>\n",
       "      <td>22155</td>\n",
       "      <td>0.811628</td>\n",
       "      <td>0.005894</td>\n",
       "      <td>0.043655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29227</th>\n",
       "      <td>6</td>\n",
       "      <td>would</td>\n",
       "      <td>4184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>would</td>\n",
       "      <td>MD</td>\n",
       "      <td>6</td>\n",
       "      <td>0.153277</td>\n",
       "      <td>25104</td>\n",
       "      <td>25104</td>\n",
       "      <td>0.919662</td>\n",
       "      <td>0.005566</td>\n",
       "      <td>0.041682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16934</th>\n",
       "      <td>7</td>\n",
       "      <td>man</td>\n",
       "      <td>3705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>man</td>\n",
       "      <td>NN</td>\n",
       "      <td>7</td>\n",
       "      <td>0.135729</td>\n",
       "      <td>25935</td>\n",
       "      <td>25935</td>\n",
       "      <td>0.950104</td>\n",
       "      <td>0.004928</td>\n",
       "      <td>0.037774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16610</th>\n",
       "      <td>8</td>\n",
       "      <td>lord</td>\n",
       "      <td>3330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>lord</td>\n",
       "      <td>NNP</td>\n",
       "      <td>8</td>\n",
       "      <td>0.121991</td>\n",
       "      <td>26640</td>\n",
       "      <td>26640</td>\n",
       "      <td>0.975931</td>\n",
       "      <td>0.004430</td>\n",
       "      <td>0.034633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17329</th>\n",
       "      <td>9</td>\n",
       "      <td>men</td>\n",
       "      <td>3037</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>men</td>\n",
       "      <td>NNS</td>\n",
       "      <td>9</td>\n",
       "      <td>0.111258</td>\n",
       "      <td>27333</td>\n",
       "      <td>27333</td>\n",
       "      <td>1.001319</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.032122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24044</th>\n",
       "      <td>10</td>\n",
       "      <td>shall</td>\n",
       "      <td>2950</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shall</td>\n",
       "      <td>MD</td>\n",
       "      <td>10</td>\n",
       "      <td>0.108070</td>\n",
       "      <td>29500</td>\n",
       "      <td>29500</td>\n",
       "      <td>1.080705</td>\n",
       "      <td>0.003924</td>\n",
       "      <td>0.031367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26493</th>\n",
       "      <td>11</td>\n",
       "      <td>things</td>\n",
       "      <td>2919</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>thing</td>\n",
       "      <td>NNS</td>\n",
       "      <td>11</td>\n",
       "      <td>0.106935</td>\n",
       "      <td>32109</td>\n",
       "      <td>32109</td>\n",
       "      <td>1.176283</td>\n",
       "      <td>0.003883</td>\n",
       "      <td>0.031096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2839</th>\n",
       "      <td>12</td>\n",
       "      <td>also</td>\n",
       "      <td>2735</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>also</td>\n",
       "      <td>RB</td>\n",
       "      <td>12</td>\n",
       "      <td>0.100194</td>\n",
       "      <td>32820</td>\n",
       "      <td>32820</td>\n",
       "      <td>1.202330</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>0.029478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23301</th>\n",
       "      <td>13</td>\n",
       "      <td>said</td>\n",
       "      <td>2729</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>said</td>\n",
       "      <td>VBD</td>\n",
       "      <td>13</td>\n",
       "      <td>0.099974</td>\n",
       "      <td>35477</td>\n",
       "      <td>35477</td>\n",
       "      <td>1.299667</td>\n",
       "      <td>0.003630</td>\n",
       "      <td>0.029425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12956</th>\n",
       "      <td>14</td>\n",
       "      <td>great</td>\n",
       "      <td>2655</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>great</td>\n",
       "      <td>JJ</td>\n",
       "      <td>14</td>\n",
       "      <td>0.097263</td>\n",
       "      <td>37170</td>\n",
       "      <td>37170</td>\n",
       "      <td>1.361688</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>0.028767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12818</th>\n",
       "      <td>15</td>\n",
       "      <td>good</td>\n",
       "      <td>2510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>JJ</td>\n",
       "      <td>15</td>\n",
       "      <td>0.091951</td>\n",
       "      <td>37650</td>\n",
       "      <td>37650</td>\n",
       "      <td>1.379272</td>\n",
       "      <td>0.003339</td>\n",
       "      <td>0.027466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27994</th>\n",
       "      <td>16</td>\n",
       "      <td>upon</td>\n",
       "      <td>2496</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>upon</td>\n",
       "      <td>IN</td>\n",
       "      <td>16</td>\n",
       "      <td>0.091439</td>\n",
       "      <td>39936</td>\n",
       "      <td>39936</td>\n",
       "      <td>1.463018</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>0.027340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18048</th>\n",
       "      <td>17</td>\n",
       "      <td>must</td>\n",
       "      <td>2425</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>must</td>\n",
       "      <td>MD</td>\n",
       "      <td>17</td>\n",
       "      <td>0.088838</td>\n",
       "      <td>41225</td>\n",
       "      <td>41225</td>\n",
       "      <td>1.510239</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.026697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26463</th>\n",
       "      <td>18</td>\n",
       "      <td>therefore</td>\n",
       "      <td>2389</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>therefor</td>\n",
       "      <td>RB</td>\n",
       "      <td>18</td>\n",
       "      <td>0.087519</td>\n",
       "      <td>43002</td>\n",
       "      <td>43002</td>\n",
       "      <td>1.575338</td>\n",
       "      <td>0.003178</td>\n",
       "      <td>0.026369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29115</th>\n",
       "      <td>19</td>\n",
       "      <td>without</td>\n",
       "      <td>2293</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>without</td>\n",
       "      <td>IN</td>\n",
       "      <td>19</td>\n",
       "      <td>0.084002</td>\n",
       "      <td>43567</td>\n",
       "      <td>43567</td>\n",
       "      <td>1.596036</td>\n",
       "      <td>0.003050</td>\n",
       "      <td>0.025490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16354</th>\n",
       "      <td>20</td>\n",
       "      <td>life</td>\n",
       "      <td>2153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>life</td>\n",
       "      <td>NN</td>\n",
       "      <td>20</td>\n",
       "      <td>0.078873</td>\n",
       "      <td>43060</td>\n",
       "      <td>43060</td>\n",
       "      <td>1.577463</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>0.024194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term_rank   term_str      n  num  stop stem_porter pos_max  \\\n",
       "term_id                                                               \n",
       "12782            1        god  13132    0     0         god     NNP   \n",
       "28025            2         us   5896    0     0          us     PRP   \n",
       "5965             3     christ   5738    0     0      christ     NNP   \n",
       "17181            4        may   4635    0     0         may      MD   \n",
       "18869            5        one   4431    0     0         one      CD   \n",
       "29227            6      would   4184    0     0       would      MD   \n",
       "16934            7        man   3705    0     0         man      NN   \n",
       "16610            8       lord   3330    0     0        lord     NNP   \n",
       "17329            9        men   3037    0     0         men     NNS   \n",
       "24044           10      shall   2950    0     0       shall      MD   \n",
       "26493           11     things   2919    0     0       thing     NNS   \n",
       "2839            12       also   2735    0     0        also      RB   \n",
       "23301           13       said   2729    0     0        said     VBD   \n",
       "12956           14      great   2655    0     0       great      JJ   \n",
       "12818           15       good   2510    0     0        good      JJ   \n",
       "27994           16       upon   2496    0     0        upon      IN   \n",
       "18048           17       must   2425    0     0        must      MD   \n",
       "26463           18  therefore   2389    0     0    therefor      RB   \n",
       "29115           19    without   2293    0     0     without      IN   \n",
       "16354           20       life   2153    0     0        life      NN   \n",
       "\n",
       "         term_rank2         p  zipf_k  zipf_k2   zipf_k3        p2         h  \n",
       "term_id                                                                       \n",
       "12782             1  0.481079   13132    13132  0.481079  0.017468  0.101998  \n",
       "28025             2  0.215994   11792    11792  0.431989  0.007843  0.054856  \n",
       "5965              3  0.210206   17214    17214  0.630619  0.007633  0.053685  \n",
       "17181             4  0.169799   18540    18540  0.679196  0.006165  0.045264  \n",
       "18869             5  0.162326   22155    22155  0.811628  0.005894  0.043655  \n",
       "29227             6  0.153277   25104    25104  0.919662  0.005566  0.041682  \n",
       "16934             7  0.135729   25935    25935  0.950104  0.004928  0.037774  \n",
       "16610             8  0.121991   26640    26640  0.975931  0.004430  0.034633  \n",
       "17329             9  0.111258   27333    27333  1.001319  0.004040  0.032122  \n",
       "24044            10  0.108070   29500    29500  1.080705  0.003924  0.031367  \n",
       "26493            11  0.106935   32109    32109  1.176283  0.003883  0.031096  \n",
       "2839             12  0.100194   32820    32820  1.202330  0.003638  0.029478  \n",
       "23301            13  0.099974   35477    35477  1.299667  0.003630  0.029425  \n",
       "12956            14  0.097263   37170    37170  1.361688  0.003532  0.028767  \n",
       "12818            15  0.091951   37650    37650  1.379272  0.003339  0.027466  \n",
       "27994            16  0.091439   39936    39936  1.463018  0.003320  0.027340  \n",
       "18048            17  0.088838   41225    41225  1.510239  0.003226  0.026697  \n",
       "26463            18  0.087519   43002    43002  1.575338  0.003178  0.026369  \n",
       "29115            19  0.084002   43567    43567  1.596036  0.003050  0.025490  \n",
       "16354            20  0.078873   43060    43060  1.577463  0.002864  0.024194  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.sort_values(by='term_rank2', ascending=True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save tables to csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC.to_csv('DOC.csv')\n",
    "LIB.to_csv('LIB.csv')\n",
    "VOCAB.to_csv('VOCAB.csv')\n",
    "TOKEN.to_csv('TOKEN.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to SQLite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sqlite3\n",
    "\n",
    "#TOKEN2 = TOKEN.drop('pos_tuple', 1)\n",
    "\n",
    "#with sqlite3.connect('mod4-corpus.db') as db:\n",
    "#    DOC.to_sql('doc', db, index=True, if_exists='replace')\n",
    "#    LIB.to_sql('lib', db, index=True, if_exists='replace')\n",
    "#    VOCAB.to_sql('vocab', db, index=True, if_exists='replace')\n",
    "#    TOKEN2.to_sql('token', db, index=True, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakdown table to view most prevalent terms & POS by author:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_terms = TOKEN.reset_index().merge(LIB.reset_index()[['book_id', 'author']], on='book_id')\n",
    "author_terms = author_terms[~author_terms.term_str.isin(sw.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "calvin_terms = author_terms[author_terms.author == 'Calvin'].term_str.value_counts(ascending=False)\n",
    "bunyan_terms = author_terms[author_terms.author == 'Bunyan'].term_str.value_counts(ascending=False)\n",
    "edwards_terms = author_terms[author_terms.author == 'Edwards'].term_str.value_counts(ascending=False)\n",
    "alexander_terms = author_terms[author_terms.author == 'Alexander'].term_str.value_counts(ascending=False)\n",
    "lewis_terms = author_terms[author_terms.author == 'Lewis'].term_str.value_counts(ascending=False)\n",
    "piper_terms = author_terms[author_terms.author == 'Piper'].term_str.value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "god          6517\n",
       "us           3840\n",
       "christ       2863\n",
       "may          2388\n",
       "one          2151\n",
       "lord         2110\n",
       "would        1875\n",
       "church       1815\n",
       "man          1538\n",
       "shall        1385\n",
       "without      1384\n",
       "therefore    1347\n",
       "faith        1330\n",
       "must         1305\n",
       "also         1270\n",
       "Name: term_str, dtype: int64"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calvin_terms.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mansoul      1293\n",
       "said         1195\n",
       "town          931\n",
       "mr            924\n",
       "also          847\n",
       "thou          658\n",
       "one           658\n",
       "lord          657\n",
       "upon          653\n",
       "christian     621\n",
       "man           615\n",
       "would         582\n",
       "come          577\n",
       "shall         534\n",
       "good          531\n",
       "Name: term_str, dtype: int64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bunyan_terms.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "god       4269\n",
       "christ    1777\n",
       "things    1277\n",
       "great     1190\n",
       "may       1119\n",
       "men        929\n",
       "shall      823\n",
       "love       813\n",
       "man        789\n",
       "much       757\n",
       "spirit     755\n",
       "would      742\n",
       "one        697\n",
       "upon       683\n",
       "nature     678\n",
       "Name: term_str, dtype: int64"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edwards_terms.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "would       468\n",
       "moral       438\n",
       "god         388\n",
       "may         360\n",
       "man         353\n",
       "men         325\n",
       "one         320\n",
       "every       252\n",
       "must        241\n",
       "reason      211\n",
       "could       202\n",
       "truth       195\n",
       "us          186\n",
       "mind        185\n",
       "religion    181\n",
       "Name: term_str, dtype: int64"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexander_terms.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "god       501\n",
       "love      492\n",
       "one       317\n",
       "us        316\n",
       "man       312\n",
       "may       300\n",
       "would     299\n",
       "even      240\n",
       "must      219\n",
       "like      214\n",
       "good      198\n",
       "need      153\n",
       "nature    145\n",
       "life      136\n",
       "say       135\n",
       "Name: term_str, dtype: int64"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lewis_terms.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "god       1203\n",
       "christ     892\n",
       "us         507\n",
       "life       463\n",
       "jesus      319\n",
       "one        288\n",
       "death      252\n",
       "people     245\n",
       "world      234\n",
       "love       222\n",
       "would      218\n",
       "glory      196\n",
       "work       182\n",
       "joy        178\n",
       "way        175\n",
       "Name: term_str, dtype: int64"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piper_terms.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS5559_Annotations.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "interpreter": {
   "hash": "8fdbed2d6e700ff1a4a1f41502e0a2d1e121d5ba4480b6581143d2f3ddb3a694"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
